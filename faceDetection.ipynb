{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "[[[145 144 141 ... 185 183 183]\n",
      "  [148 147 145 ... 173 174 174]\n",
      "  [150 150 149 ... 162 164 164]\n",
      "  ...\n",
      "  [184 186 188 ... 182 184 184]\n",
      "  [184 186 188 ... 183 184 184]\n",
      "  [184 185 188 ... 183 183 183]]\n",
      "\n",
      " [[146 149 149 ...  96 111  90]\n",
      "  [149 154 144 ... 108 116  86]\n",
      "  [146 145 149 ... 100 104  89]\n",
      "  ...\n",
      "  [202 205 207 ... 238 238 238]\n",
      "  [206 199 193 ... 233 238 238]\n",
      "  [200 202 180 ... 237 236 236]]\n",
      "\n",
      " [[158 159 154 ... 158 149 145]\n",
      "  [161 157 150 ... 154 154 156]\n",
      "  [152 145 154 ... 152 148 146]\n",
      "  ...\n",
      "  [212 207 210 ... 160 160 166]\n",
      "  [210 210 210 ... 171 170 175]\n",
      "  [209 213 210 ... 184 178 182]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[136 135 133 ... 153 148 150]\n",
      "  [155 145 137 ... 149 152 152]\n",
      "  [150 137 136 ... 159 146 146]\n",
      "  ...\n",
      "  [179 106 114 ... 202 195 188]\n",
      "  [155  86 190 ... 205 187 181]\n",
      "  [101 135 187 ... 207 191 185]]\n",
      "\n",
      " [[149 150 148 ... 153 144 136]\n",
      "  [148 147 145 ... 148 161 146]\n",
      "  [149 149 150 ... 150 151 147]\n",
      "  ...\n",
      "  [184 187 183 ... 232 230 230]\n",
      "  [180 188 147 ... 233 232 232]\n",
      "  [191 166 113 ... 233 232 232]]\n",
      "\n",
      " [[147 154 147 ... 161 160 163]\n",
      "  [149 146 147 ... 157 165 157]\n",
      "  [160 150 155 ... 161 152 145]\n",
      "  ...\n",
      "  [188 188 189 ... 240 238 234]\n",
      "  [192 191 192 ... 240 240 236]\n",
      "  [194 193 194 ... 240 241 238]]] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n",
      "vaibhav\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy, os\n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "dataset = 'dataset'\n",
    "print('Training....')\n",
    "\n",
    "(images,labels,names,id) = ([],[],{},0)\n",
    "\n",
    "for (subdirs, dirs, files) in os.walk(dataset):\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(dataset, subdir)\n",
    "        for filename in os.listdir(subjectpath):\n",
    "            path = subjectpath + '/' + filename\n",
    "            label = id\n",
    "            images.append(cv2.imread(path,0))\n",
    "            labels.append(int(label))\n",
    "        id = id + 1\n",
    "\n",
    "(images,labels) = [numpy.array(lis) for lis in [images,labels]]\n",
    "print(images, labels)\n",
    "(width,height) = (130,100)\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "#model = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "model.train(images, labels)\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "cnt = 0\n",
    "\n",
    "while True:\n",
    "    (_,im) = webcam.read()\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "        face = gray[y:y+h,x:x+w]\n",
    "        face_resize = cv2.resize(face,(width,height))\n",
    "\n",
    "        prediction = model.predict(face_resize)\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "        if prediction[1] < 800:\n",
    "            cv2.putText(im,'%s - %.0f' % (names[prediction[0]],prediction[1]),(x-10,y-10),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255))\n",
    "            print(names[prediction[0]])\n",
    "            cnt = 0\n",
    "        else:\n",
    "            cnt += 1\n",
    "            cv2.putText(im,'Unknown',(x-10,y-10),cv2.FONT_HERSHEY_PLAIN,1,(0,255,0))\n",
    "            if cnt > 100:\n",
    "                print(\"Unknown Person\")\n",
    "                cv2.imwrite(\"Unknown.jpg\",im)\n",
    "                cnt = 0\n",
    "    cv2.imshow('FaceRecognition',im)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        break\n",
    "webcam.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
